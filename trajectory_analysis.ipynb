{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yabmtm/packages/miniconda3/envs/msm/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from __future__ import print_function\n",
    "import glob, itertools, os, subprocess, re\n",
    "import sys, time, tqdm, itertools, socket\n",
    "import mdtraj as md\n",
    "import msmbuilder.utils\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import groupby, count\n",
    "import matplotlib\n",
    "# Script: matplotlib.use('Agg')  | Notebook: %matplotlib inline\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from msmbuilder.cluster import KCenters, KMedoids\n",
    "from msmbuilder.decomposition import tICA\n",
    "from msmbuilder.featurizer import AtomPairsFeaturizer\n",
    "from msmbuilder.msm import ContinuousTimeMSM, implied_timescales, MarkovStateModel\n",
    "from operator import itemgetter\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "'''This script has lots of functionality and is based on analyzing Gromacs trajectories. A list of trajectory\n",
    "   files is given as trajectory_files, as well as a general structure file. Other structure files should contain\n",
    "   the same name as the corresponding trajectory file, e.g. traj_001.trr traj_001.gro.\n",
    "'''\n",
    "\n",
    "# TODO: add interactivity\n",
    "# ADD loader function\n",
    "# do we need the pkl files in calculating components?\n",
    "# add threading for parallel feature selections\n",
    "# add metric for comparing overlaps given feature selections\n",
    "# make sure cluster centers are saving properly\n",
    "# should i plot traj end point as well?\n",
    "# correct movie and eigenvector analysis functions\n",
    "# add autocorrelation function\n",
    "\n",
    "  \n",
    "def calculate_distances():\n",
    "    \n",
    "    \"\"\"Calculate pair-wise distance features and save as .npy files. Index selection is done within the function.\n",
    "       Feature labels are returned to match tICA components back to the features that make them up.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCalculating distances...\")\n",
    "    for i in range(len(trajectory_files)): # For each trajectory file\n",
    "        ions,indices = [],[]\n",
    "        if '.gro' in trajectory_files[i]:\n",
    "            traj = md.load(trajectory_files[i]) # Load trajectory as single frame\n",
    "            print(\"\\nLoaded \" + trajectory_files[i] + \" as a single frame\")\n",
    "        else:\n",
    "            try: # Try to load with structure file matching trajectory name\n",
    "                structure = trajectory_files[i].split('.')[0] + '.gro'\n",
    "                traj = md.load(trajectory_files[i], top=structure)\n",
    "                print(\"Loaded \" + trajectory_files[i] + \" with top: \" + structure)\n",
    "            except Exception as e: # Else try loading trajectory with general structure file\n",
    "                traj = md.load(trajectory_files[i], top=structure_file)\n",
    "                print(\"Loaded \" + trajectory_files[i] + \" with top: \" + structure_file)\n",
    "\n",
    "###################\n",
    "            \n",
    "#      INDEX SELECTION\n",
    "\n",
    "        bk_carbon = [ a.index for a in traj.topology.atoms if a.name in ['C','CA'] and a.residue.name not in ['TFL']]\n",
    "        bk_oxygen = [ a.index for a in traj.topology.atoms if a.name == 'O' and a.residue.name not in ['TFL']]\n",
    "        ions = [ a.index for a in traj.topology.atoms if a.name in ['NA','K'] ]\n",
    "        all_oxygen = [ a.index for a in traj.topology.atoms if a.element.symbol == 'O' and a.residue.name not in ['TFL','MOE']]\n",
    "        all_carbon = [ a.index for a in traj.topology.atoms if a.element.symbol == 'C' and a.residue.name not in ['TFL']]\n",
    "\n",
    "        indices += bk_oxygen\n",
    "#        indices += all_carbon\n",
    "#        indices += ions\n",
    "\n",
    "###################\n",
    "\n",
    "        # Transform indices into distances and save\n",
    "        pairs = list(itertools.combinations(indices, 2))\n",
    "        feature_labels = [[[str(traj.topology.atom(j[0]).residue.index) +\n",
    "                            traj.topology.atom(j[0]).residue.name,traj.topology.atom(j[0]).name],\n",
    "                          [str(traj.topology.atom(j[1]).residue.index) + \n",
    "                           traj.topology.atom(j[1]).residue.name,traj.topology.atom(j[1]).name]] for j in pairs]\n",
    "        \n",
    "        features = AtomPairsFeaturizer(pairs)\n",
    "        transformed_data = features.fit_transform(traj)\n",
    "        \n",
    "        for j in range(len(transformed_data)):\n",
    "            transformed_data[j] = transformed_data[j][0]\n",
    "            \n",
    "        print(\"Saved %d pair-wise distance features over %d frames.\\n\" %(len(pairs),len(transformed_data)))\n",
    "        np.save(project_title + '/' + 'distance_out_' + str(i).zfill(3) + '.npy', transformed_data)\n",
    "        \n",
    "    return feature_labels\n",
    "\n",
    "\n",
    "def get_bound_frames():\n",
    "    \n",
    "    '''Returns a list of lists (for each trajectory) of lists (for each binding event) of frame numbers that\n",
    "       contain binding events based on the bound_cutoff parameter. If no binding events are found, that\n",
    "       trajectory is reported as None. Binding events are characterized by indices assigned below.\n",
    "    '''\n",
    "    \n",
    "    # Initiate lists\n",
    "    all_bound_frames,all_binding_distances,_averages = [],[],[]\n",
    "    \n",
    "    # Load trajectory data\n",
    "    for i in range(len(trajectory_files)): # For each trajectory\n",
    "        try: # Try loading with general structure file\n",
    "            traj = md.load(trajectory_files[i], top=structure_file)\n",
    "        except Exception as e: # Else load with structure file matching trajectory name\n",
    "            structure = trajectory_files[i].split('.')[0] + '.gro'\n",
    "            traj = md.load(trajectory_files[i], top=structure)\n",
    "\n",
    "            \n",
    "        # Get indices target (backbone oxygens) and ligand (cations)   \n",
    "        target = [ a.index for a in traj.topology.atoms if a.name == 'O' and a.residue.name in ['PR1','MOE'] and a.residue.index % 2 == 1]\n",
    "        ligand = [ a.index for a in traj.topology.atoms if a.name in ['NA','K'] ]\n",
    "            \n",
    "        if ligand: # If this simulation contains ligands\n",
    "            bound_frames,binding_indices = [],[]\n",
    "            print(\"Checking bound frames in \" + trajectory_files[i])\n",
    "            for j in target: # Determine distance pairs\n",
    "                for k in ligand:\n",
    "                    binding_indices.append([j,k])\n",
    "                    \n",
    "            # Compute distances\n",
    "            binding_distances = md.compute_distances(traj,binding_indices)\n",
    "            for j in range(len(binding_distances)):\n",
    "                for k in range(len(binding_distances[j])):\n",
    "                    if binding_distances[j][k] < bound_cutoff:\n",
    "                        bound_frames.append(j)\n",
    "                        \n",
    "            # Transforms distances to an average of target index to each ligand index.\n",
    "            # This is used to calculate the distance of each ion from the center of the macrocycle\n",
    "            # and can be deleted for non-similar systems.\n",
    "            \n",
    "            for j in range(len(binding_distances)): # For each frame\n",
    "                averages = []\n",
    "                for k in range(len(ligand)): # For each ligand index (4 cations)\n",
    "                    distances_per_ligand = []\n",
    "                    for m in range(len(binding_distances[0])): # For each binding distance {ligand(4) * target(6) = 24}\n",
    "                        if m % len(ligand) == k: # Separate binding frames per ligand index (ion)\n",
    "                            distances_per_ligand.append(binding_distances[j][m])\n",
    "                    averages.append(np.average(distances_per_ligand)) # Calculate average binding distance\n",
    "                _averages.append(averages)\n",
    "            binding_distances = _averages\n",
    "                        \n",
    "            # Separate bound frames into lists of binding events\n",
    "            all_bound_frames.append([list(g) for f, g in groupby(list(set(bound_frames)), key=lambda a,b=count(): a-next(b))])\n",
    "            length = max([len(i) for i in all_bound_frames[-1]])\n",
    "            all_binding_distances.append(binding_distances)\n",
    "            \n",
    "        else: # If no ligands are present\n",
    "            all_bound_frames.append(None)\n",
    "            all_binding_distances.append(None)\n",
    "            \n",
    "    return all_bound_frames, all_binding_distances\n",
    "     \n",
    "\n",
    "def get_dihedral_indices(traj,structure_file,angle):\n",
    "    \n",
    "    '''Returns a list of indices and a list of all possible cis/trans isomers given a trajectory file,\n",
    "       a structure file, and a particular dihedral angle. Choices for dihedral angles include omega, phi,\n",
    "       and psi. The indices used are based on the nmer and cyclic parameters.'''\n",
    "    \n",
    "    # Change nmer to range of residue numbers to use, so it's more applicable to proteins.\n",
    "    \n",
    "    indices = []\n",
    "    for i in range(nmer):\n",
    "        indices.append([])\n",
    "        if angle == 'omega':\n",
    "            if i != nmer-1:\n",
    "                for k in ['CA','C']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i:\n",
    "                            indices[i].append(a.index)\n",
    "                for k in ['N','CA']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i+1:\n",
    "                            indices[i].append(a.index)\n",
    "            elif i == nmer-1 and cyclic:\n",
    "                for k in ['CA','C']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i:\n",
    "                            indices[i].append(a.index)\n",
    "                for k in ['N','CA']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == 0:\n",
    "                            indices[i].append(a.index)\n",
    "        elif angle == 'phi':\n",
    "            if i != nmer-1:\n",
    "                for k in ['C','N']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i:\n",
    "                            indices[i].append(a.index)\n",
    "                for k in ['CA','C']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i+1:\n",
    "                            indices[i].append(a.index)\n",
    "            elif i == nmer-1 and cyclic:\n",
    "                for k in ['C','N']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i:\n",
    "                            indices[i].append(a.index)\n",
    "                for k in ['CA','C']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == 0:\n",
    "                            indices[i].append(a.index)\n",
    "        elif angle == 'psi':\n",
    "            if i != nmer-1:\n",
    "                for k in ['N','CA']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i:\n",
    "                            indices[i].append(a.index)\n",
    "                for k in ['C','N']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i+1:\n",
    "                            indices[i].append(a.index)\n",
    "            elif i == nmer-1 and cyclic:\n",
    "                for k in ['N','CA']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == i:\n",
    "                            indices[i].append(a.index)\n",
    "                for k in ['C','N']:\n",
    "                    for a in traj.topology.atoms:\n",
    "                        if a.name == k and a.residue.index == 0:\n",
    "                            indices[i].append(a.index)\n",
    "\n",
    "\n",
    "    # Populate a list of all possible cis/trans conformations.\n",
    "    choices = [''.join(i) for i in itertools.product(['c','t'], repeat = nmer)]\n",
    "    return indices, choices\n",
    "\n",
    "\n",
    "def calculate_dihedrals():\n",
    "    \n",
    "    \"\"\"Calculate dihedral features and save as .npy files. Residue selection is done using the nmer and cyclic\n",
    "       parameters. Feature labels are returned to match tICA components back to the features that make them up.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nCalculating Dihedrals...\")\n",
    "          \n",
    "    for i in tqdm.tqdm_notebook(range(len(trajectory_files))):\n",
    "         \n",
    "        # Load trajectory and get dihedral indices\n",
    "        try: # Try loading with general structure file\n",
    "            traj = md.load(trajectory_files[i], top=structure_file)\n",
    "            indices,choices = get_dihedral_indices(traj,structure_file,angle)\n",
    "            print(\"\\nLoaded \" + trajectory_files[i] + \" with top: \" + structure_file)\n",
    "          \n",
    "        except Exception as e: # Else load with structure file matching trajectory name\n",
    "            indices,choices = get_dihedral_indices(traj,structure,angle)\n",
    "            print(\"\\nLoaded \" + trajectory_files[i] + \" with top: \" + structure)\n",
    "\n",
    "        # Compute Dihedrals\n",
    "        dihedral_quartets = np.asarray(indices)\n",
    "        thetas = md.compute_dihedrals(traj, dihedral_quartets)\n",
    "        \n",
    "        # Stack sines and cosines to preserve the 2D nature of ~*~AnGlEs~*~\n",
    "        sin_cos_dihedrals = np.hstack([np.sin(thetas), np.cos(thetas)])\n",
    "        # Save dihedral features as .npy\n",
    "        np.save(project_title + '/' + 'dihedral_out_' + str(i).zfill(3) + '.npy', sin_cos_dihedrals)\n",
    "        \n",
    "        print(\"Saving %d dihedral features for %s\" %(len(thetas),trajectory_files[i]))\n",
    "\n",
    "        feature_labels = [[[str(traj.topology.atom(j[0]).residue.index) +\n",
    "                            traj.topology.atom(j[0]).residue.name,traj.topology.atom(j[0]).name],\n",
    "                          [str(traj.topology.atom(j[1]).residue.index) + \n",
    "                           traj.topology.atom(j[1]).residue.name,traj.topology.atom(j[1]).name],\n",
    "                          [str(traj.topology.atom(j[2]).residue.index) + \n",
    "                           traj.topology.atom(j[2]).residue.name,traj.topology.atom(j[2]).name],\n",
    "                          [str(traj.topology.atom(j[3]).residue.index) + \n",
    "                           traj.topology.atom(j[3]).residue.name,traj.topology.atom(j[3]).name]] for j in indices]\n",
    "        \n",
    "        feature_labels = np.hstack([['sin' + str(i) for i in feature_labels],['cos' + str(i) for i in feature_labels]])\n",
    "        \n",
    "    return feature_labels\n",
    "\n",
    "          \n",
    "def color_by_cistrans(traj,structure_file,angle):\n",
    "          \n",
    "    '''This function is particularly specialized and returns an array of color strings denoting the number of\n",
    "       trans angles in each frame. It can be generalized by changing options to reflect the number of dihedrals\n",
    "       and to change how nmer works.'''\n",
    "    \n",
    "    # Load each trajectory\n",
    "    print(traj,structure_file)\n",
    "    traj = md.load(traj,top=structure_file)\n",
    "    # Determine dihedral indices\n",
    "    indices = get_dihedral_indices(traj,structure_file,angle)[0]\n",
    "    # Each color represents a number of trans angles (0-6)\n",
    "    options = ['pink','red','orange','green','blue','purple','black']\n",
    "    # Compute dihedrals\n",
    "    dihedrals = md.compute_dihedrals(traj, np.asarray(indices))\n",
    "    results = []\n",
    "          \n",
    "    for i in range(len(dihedrals)): # For each frame\n",
    "        dihedral_string = []\n",
    "        for j in range(len(dihedrals[i])): # For each angle\n",
    "            # Determine whether each angle is cis or trans.\n",
    "            if dihedrals[i][j] >= -1.57 and dihedrals[i][j] < 1.57:\n",
    "                dihedral_string.append(\"c\")\n",
    "            elif dihedrals[i][j] < -1.57 or dihedrals[i][j] >= 1.57:\n",
    "                dihedral_string.append(\"t\")\n",
    "\n",
    "        results.append(options[dihedral_string.count('t')])\n",
    "                \n",
    "    return results\n",
    "\n",
    "\n",
    "    \n",
    "def calculate_tica_components():\n",
    "          \n",
    "    '''Load in the features, calculate a given number of tICA components (tica_components) given a\n",
    "       lagtime (lag_time), and save tICA coordinates and eigenvector data. It then creates and populates\n",
    "       a list for each desired component, clusters the data, saving normalized populations as populations.dat\n",
    "       and saving each cluster center as a .pdb. tICA plots are created and saved, and implied timescales are\n",
    "       calculated, saved, and plotted.\n",
    "    '''\n",
    "          \n",
    "    print(\"\\nCalculating tICA components...\")\n",
    "          \n",
    "    # Load in feature files\n",
    "    feature_files = sorted(glob.glob(project_title + '/' + \"*out*npy\"))\n",
    "    features = [ np.load(filename) for filename in feature_files]\n",
    "\n",
    "    # Perform tICA calculation\n",
    "    tica_coordinates = tICA(lag_time=tica_lagtime,\n",
    "        n_components=int(tica_components)).fit_transform(features)\n",
    "    eigen_data = tICA(lag_time=tica_lagtime,\n",
    "        n_components=int(tica_components)).fit(features)\n",
    "          \n",
    "    np.save(project_title + '/' + 'lag_%d_comp_%d.npy' %(tica_lagtime, tica_components), tica_coordinates)\n",
    "    np.save(project_title + '/' + 'lag_%d_eigen.npy' %tica_lagtime, eigen_data)\n",
    "          \n",
    "    # Extract tICA eigenvectors\n",
    "    eigenvectors = np.transpose(eigen_data.eigenvectors_)\n",
    "          \n",
    "    # Initiate and populate an array for each component    \n",
    "    for i in range(tica_components):\n",
    "        exec('tica_' + str(i+1) + ' = []')\n",
    "          \n",
    "    for i in tqdm.tqdm(range(len(features))):\n",
    "        for j in range(len(tica_coordinates[i])):\n",
    "            for k in range(tica_components):\n",
    "                exec('tica_' + str(k+1) + '.append(tica_coordinates[i][j][k])')\n",
    "            \n",
    "    # Perform clustering based on the cluster_method parameter.\n",
    "    if cluster_method == 'kcenters':\n",
    "        print(\"Clustering via KCenters...\")\n",
    "        clusters = KCenters(n_clusters)\n",
    "    elif cluster_method == 'kmeans':\n",
    "        print(\"Clustering via KMeans...\")\n",
    "        clusters = KMeans(n_clusters)\n",
    "    else:\n",
    "        sys.exit(\"Invalid cluster_method. Use kmeans or kcenters.\")\n",
    "     \n",
    "    # Determine cluster assignment for each frame.      \n",
    "    sequences = clusters.fit_transform(tica_coordinates)\n",
    "    np.save(project_title + '/' + 'lag_%d_clusters_%d_sequences.npy' %(tica_lagtime, n_clusters), sequences)\n",
    "    np.save(project_title + '/' + 'lag_%d_clusters_%d_center.npy' %(tica_lagtime, n_clusters),\n",
    "        clusters.cluster_centers_)\n",
    "\n",
    "#    if enspara_msm:\n",
    "#        from enspara.msm import MSM, builders\n",
    "\n",
    "        # build the MSM fitter with a lag time of 100 (frames) and\n",
    "        # using the transpose method\n",
    "#        msm = MSM(lag_time=100, method=builders.transpose)\n",
    "\n",
    "        # fit the MSM to your assignments (a numpy ndarray or ragged array)\n",
    "#        msm.fit(assignments)\n",
    "\n",
    "#        print(msm.tcounts_)\n",
    "#        print(msm.tprobs_)\n",
    "#        print(msm.eq_probs_)\n",
    "        \n",
    "    # Determine cluster populations, normalize the counts, and save as percentages for\n",
    "    # labeling if a cluster contains more than cluster_percentage_cutoff percent of the data.\n",
    "    # Finally, save normalized counts.\n",
    "    print(\"\\nDetermining cluster populations...\")\n",
    "    \n",
    "    if not os.path.exists(project_title + '/cluster_centers'):\n",
    "        os.makedirs(project_title + '/cluster_centers')\n",
    "    counts = np.array([len(np.where(np.concatenate(sequences)==i)[0]) for i in range(n_clusters)])\n",
    "    normalized_counts =  counts/float(counts.sum())\n",
    "    percentages = [ i*100 for i in normalized_counts ]\n",
    "    population_labels = [ [i,\"%.2f\"%percentages[i]] for i in range(len(percentages)) if percentages[i] > cluster_percentage_cutoff ]\n",
    "    np.savetxt(project_title + '/cluster_centers/populations.dat', normalized_counts)\n",
    "\n",
    "\n",
    "    # Plot all unique combinations of tICA components\n",
    "    print(\"\\nPlotting tICA components with cluster centers...\")\n",
    "    all_ticas = list(itertools.permutations(range(1,tica_components+1), 2))\n",
    "    for j in tqdm.tqdm(range(len(all_ticas))): # For each pair\n",
    "        if all_ticas[j][0] < all_ticas[j][1]:\n",
    "            plt.figure(j, figsize=(20,16))\n",
    "            plt.hexbin(eval(\"tica_\"+str(all_ticas[j][0])), eval(\"tica_\"+str(all_ticas[j][1])), bins='log')\n",
    "            x_centers = [clusters.cluster_centers_[i][all_ticas[j][0]-1] for i in range(len(clusters.cluster_centers_))]\n",
    "            y_centers = [clusters.cluster_centers_[i][all_ticas[j][1]-1] for i in range(len(clusters.cluster_centers_))]\n",
    "            high_pop_x_centers = [ x_centers[i] for i in range(len(x_centers)) if percentages[i] > cluster_percentage_cutoff ]\n",
    "            high_pop_y_centers = [ y_centers[i] for i in range(len(y_centers)) if percentages[i] > cluster_percentage_cutoff ]\n",
    "            plt.plot(x_centers, y_centers, color='y', linestyle=\"\", marker=\"o\")\n",
    "            plt.plot(eval(\"tica_\"+str(all_ticas[j][0])+'[0]'), eval(\"tica_\"+str(all_ticas[j][1])+'[0]'), color='k', marker='*',markersize=24)\n",
    "            plt.xlabel('tic'+str(all_ticas[j][0]))\n",
    "            plt.ylabel('tic'+str(all_ticas[j][1]))\n",
    "            plt.title(project_title)\n",
    "            # Add labels for high-population cluster centers\n",
    "            for label, x, y in zip(population_labels, high_pop_x_centers, high_pop_y_centers):\n",
    "                plt.annotate(\n",
    "                  label,\n",
    "                  xy = (x, y), xytext = (-15, 15),\n",
    "                  textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
    "                  bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
    "                  arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "            plt.savefig(project_title + '/' + 'tica_'+str(all_ticas[j][0])+'_'+str(all_ticas[j][1])+'.png')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    # Calculate and save cluster entropy\n",
    "    print(\"\\nDetermining cluster entropy\")\n",
    "    cluster_entropy = (-1.0*normalized_counts*np.log(normalized_counts)).sum()\n",
    "    print(np.shape(cluster_entropy))\n",
    "    print(cluster_entropy)\n",
    "#    np.savetxt(project_title + '/' + 'cluster_entropy.dat', cluster_entropy)\n",
    "\n",
    "          \n",
    "    # Write out PDBs for each cluster center\n",
    "    print(\"Performing cluster analytics and saving center PDBs...\\n\")\n",
    "\n",
    "    for i in range(len(features)):\n",
    "        n_snapshots = len(clusters.distances_[i])\n",
    "          \n",
    "        # Determine frames that are cluster centers\n",
    "        cluster_indices = np.arange(n_snapshots)[ (clusters.distances_[i] < 1e-6) ]\n",
    "        print('cluster_indices',cluster_indices)\n",
    "        \n",
    "        # Determine number of each cluster, correlates to populations.dat\n",
    "        cluster_labels = sequences[i][cluster_indices]\n",
    "        print('cluster_labels',cluster_labels)\n",
    "\n",
    "        print(cluster_labels,cluster_indices)\n",
    "        # Print information on each cluster center\n",
    "        if cluster_indices.size != 0 and verbose:\n",
    "            for j in range(len(cluster_labels)): # for each cluster center found in this trajectory\n",
    "                print('Cluster center', cluster_labels[j], 'was found in trajectory ' + str(features[i]) + '.')\n",
    "                print('It is found on frame', cluster_indices[j], 'and has a relative population of %.3f'%normalized_counts[cluster_labels[0]]*100 + '%.')\n",
    "\n",
    "        # Save each cluster center as a pdb\n",
    "        for j in range(len(cluster_indices)): # actually saving the snapshots\n",
    "            try:\n",
    "                print(\"Attempting to save cluster center %d from frame %d of %s\"%(cluster_labels[j],cluster_indices[j],trajectory_files[i]))\n",
    "            except:\n",
    "                print(cluster_labels,cluster_indices,j,trajectory_files,i)\n",
    "            try: # Catches any other errors\n",
    "                try: # Catches invalid structure file\n",
    "                    cluster_traj = md.load_frame(trajectory_files[i], cluster_indices[j], top=structure_file)\n",
    "                    cluster_traj.save_pdb(project_title + '/cluster_centers/state_%d_%.3f.pdb'%(cluster_labels[j],normalized_counts[j]))\n",
    "                except Exception as e:\n",
    "                    structure = trajectory_files[i].split('.')[0] + '.gro'\n",
    "                    cluster_traj = md.load_frame(trajectory_files[i], cluster_indices[j], top=structure)\n",
    "                    cluster_traj.save_pdb(project_title + '/cluster_centers/state_%d_%.3f.pdb'%(cluster_labels[j],normalized_counts[j]))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "   # Calculate and save Implied Timescales\n",
    "    print(\"\\nCalculating Implied Timescales...\")\n",
    "    timescales = implied_timescales(sequences, lagtimes, n_timescales=n_timescales,\n",
    "        msm=MarkovStateModel(verbose=False))\n",
    "          \n",
    "    numpy_timescale_data = project_title + '/' + 'lag_%d_clusters_%d_timescales.npy' %(tica_lagtime, n_clusters)\n",
    "    np.savetxt(project_title + '/' + 'lagtimes.txt', lagtimes)\n",
    "    np.save(numpy_timescale_data, timescales)\n",
    "   \n",
    "    # Plot Implied Timescales per lagtime\n",
    "    print(\"\\nPlotting Implied Timescales...\")\n",
    "    for i in tqdm.tqdm(range(n_timescales)):\n",
    "        plt.figure(42)\n",
    "        plt.plot(lagtimes * time_step, timescales[:, i] * time_step, 'o-')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('lagtime (1e-1 ns)') # Is this scale always true?\n",
    "        plt.ylabel('Implied timescales (1e-1 ns)') # This one?\n",
    "        plt.title(project_title + ' Implied timescales')\n",
    "        plt.savefig(project_title + '/' + 'lag_%d_clusters_%d_.png' %(tica_lagtime, n_clusters))\n",
    "\n",
    "    return eigenvectors\n",
    "\n",
    "          \n",
    "def trajectory_trace():\n",
    "    \n",
    "    '''This function will load in tICA coordinates for a multiple-trajectory tICA landscape and\n",
    "       project individual trajectories upon it. It will also search for bound frames, as determined\n",
    "       by the get_bound_frames function, plotting these frames on top of the trajectory trace.\n",
    "       The projection is plotted upon the landscape with a stride variable denoted below.'''      \n",
    "        \n",
    "    print(\"\\nEvaluating Trajectory Traces...\")\n",
    "    \n",
    "    # Determine bound frames, if any\n",
    "    bound_frames = get_bound_frames()[0]\n",
    "          \n",
    "    # Load in tICA coordinates\n",
    "    tica_coordinates = np.load(project_title + '/' + 'lag_%d_comp_%d.npy' %(tica_lagtime, tica_components))\n",
    "          \n",
    "    # Populate an array for each tICA component\n",
    "    for i in range(tica_components):\n",
    "        exec('tica_' + str(i+1) + ' = []')\n",
    "    for i in range(len(tica_coordinates)):\n",
    "        for j in range(len(tica_coordinates[i])):\n",
    "            for k in range(tica_components):\n",
    "                exec('tica_' + str(k+1) + '.append(tica_coordinates[i][j][k])')\n",
    "    \n",
    "    # Determine stride of projection, and a different color for each trajectory\n",
    "    stride = int(len(tica_coordinates[0])/1000) + 1\n",
    "    colors = cm.rainbow(np.linspace(0,1,len(tica_coordinates)))\n",
    "    # Font-size changed for paper\n",
    "    matplotlib.rcParams.update({'font.size': 32})\n",
    "        \n",
    "    # Create a plot for each desired tICA component combination\n",
    "    for j in tqdm.tqdm_notebook(range(len(all_ticas))):\n",
    "        if all_ticas[j][0] < all_ticas[j][1]:\n",
    "            if not os.path.exists(project_title + \"/%d_%d\" %(all_ticas[j][0],all_ticas[j][1])):\n",
    "                os.makedirs(project_title + \"/%d_%d\" %(all_ticas[j][0],all_ticas[j][1]))\n",
    "                \n",
    "            # Create a plot for each trajectory\n",
    "            for k in range(len(trajectory_files)):\n",
    "                legend_elements,traj_tic1,traj_tic2 = [],[],[]\n",
    "                plt.figure(j, figsize=(20,15))\n",
    "                plt.hexbin(eval(\"tica_\"+str(all_ticas[j][0])), eval(\"tica_\"+str(all_ticas[j][1])), bins='log')\n",
    "                \n",
    "                # Populate arrays with tICA coordinates for a particular trajectory\n",
    "                for l in range(len(tica_coordinates[k])):\n",
    "                    traj_tic1.append(tica_coordinates[k][l][all_ticas[j][0]-1])\n",
    "                    traj_tic2.append(tica_coordinates[k][l][all_ticas[j][1]-1])\n",
    "                \n",
    "                if len(tica_coordinates[k]) == 1: # If this trajectory represents a single frame, plot it as a star\n",
    "                    plt.plot(traj_tic1, traj_tic2, color='w', marker='*')\n",
    "                else: # Otherwise, project it onto the landscape and plot its starting point as a star\n",
    "                    plt.plot(traj_tic1, traj_tic2, color=colors[k], linestyle=\"\", marker=\"o\")\n",
    "                    plt.plot(traj_tic1[0], traj_tic2[0], color='k', marker='*')\n",
    "                print(np.shape(bound_frames), np.shape(bound_frames[k]), len(traj_tic1))\n",
    "                if bound_frames[k]: # If bound frames exist\n",
    "                    for m in range(len(bound_frames[k])):\n",
    "                        try:\n",
    "                            bound_x_centers = [ traj_tic1[x] for x in bound_frames[k][m] ]\n",
    "                            bound_y_centers = [ traj_tic2[x] for x in bound_frames[k][m] ]\n",
    "                        except Exception as e:\n",
    "                            print(e,k,m,trajectory_files[k])\n",
    "                        # Project them on top of the trajectory projection in white\n",
    "                        plt.plot(bound_x_centers[::stride], bound_y_centers[::stride], color='w')\n",
    "                # Create a legend denoting which trajectory file is plotted in which color\n",
    "                legend_elements.append(Line2D([0], [0], marker='o', color=colors[k], label=trajectory_files[k],\n",
    "                  markerfacecolor=colors[k], markersize=8))\n",
    "                plt.xlabel(\"tica_\"+str(all_ticas[j][0]))\n",
    "                plt.ylabel(\"tica_\"+str(all_ticas[j][1]))\n",
    "                plt.legend(handles=legend_elements, loc='best')\n",
    "                plt.savefig(project_title + \"/%d_%d/\"%(all_ticas[j][0],all_ticas[j][1]) + \"traj_%d_trace.png\" %k)\n",
    "                plt.close()\n",
    "                \n",
    "\n",
    "\n",
    "def eigenvalue_analysis():\n",
    "    \n",
    "    '''Plots eigenvectors / corresponding features for each tICA component and sorts them and...\n",
    "   \n",
    "    '''\n",
    "    print('Performing Eigenvector Analysis')\n",
    "    \n",
    "    tica_coordinates = np.load(project_title + '/' + 'lag_%d_comp_%d.npy' %(tica_lagtime, tica_components))\n",
    "    \n",
    "    for i in range(tica_components):\n",
    "        exec('tica_' + str(i+1) + ' = []')\n",
    "    for i in range(len(tica_coordinates)): # this takes a while\n",
    "        for j in range(len(tica_coordinates[i])):\n",
    "            for k in range(tica_components):\n",
    "                exec('tica_' + str(k+1) + '.append(tica_coordinates[i][j][k])')\n",
    "                \n",
    "    try:\n",
    "        sorted_eigenvectors = [sorted(x) for x in eigenvectors]\n",
    "    except NameError:\n",
    "        eigenvectors = calculate_tica_components()\n",
    "        sorted_eigenvectors = [sorted(x) for x in eigenvectors]\n",
    "        \n",
    "    sorted_eigenindices = [np.argsort(x) for x in eigenvectors]\n",
    "    \n",
    "    plt.figure(0)\n",
    "    for i in range(tica_components):\n",
    "        plt.subplot(int(\"42\" + str(i+1)))\n",
    "        plt.bar(range(len(eigenvectors[i])),eigenvectors[i])\n",
    "    plt.title('Unsorted Eigenvectors')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(project_title + '/' + \"unsorted_eigenvectors\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(1)\n",
    "    for i in range(tica_components):\n",
    "        plt.subplot(int(\"42\" + str(i+1)))\n",
    "        plt.bar(range(len(sorted_eigenvectors[i])),sorted_eigenvectors[i])\n",
    "    plt.title('Sorted Eigenvectors')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(project_title + '/' + \"sorted_eigenvectors\")\n",
    "    plt.close('all')\n",
    "    \n",
    "        \n",
    "    for i in range(len(feature_labels)):\n",
    "        exec('y_' + str(i+1) + ' = []')\n",
    "        exec('labels_' + str(i+1) + ' = []')\n",
    "\n",
    "    for i in range(tica_components):\n",
    "        for j in range(len(feature_labels)): #list(range(5)) + list(range(-1,-6,-1)):\n",
    "            exec('y_' + str(i+1) + '.append(sorted_eigenvectors[i][j])')\n",
    "            exec('labels_' + str(i+1) + '.append(feature_labels[sorted_eigenindices[i][j]])')\n",
    "        \n",
    "    for j in range(len(all_ticas)):\n",
    "        if all_ticas[j][0] < all_ticas[j][1]:\n",
    "            plt.figure(j+777, figsize=(15,30)) # plotting tica_1, tica_2\n",
    "            plt.subplot(211)\n",
    "            plt.hexbin(eval(\"tica_\"+str(all_ticas[j][0])), eval(\"tica_\"+str(all_ticas[j][1])), bins='log') #, cmap=cmaps.viridis\n",
    "            plt.subplot(413)\n",
    "            plt.bar(range(len(eval(\"y_\" + str(all_ticas[j][0])))), eval(\"y_\" + str(all_ticas[j][0])))\n",
    "            plt.xticks(range(len(eval(\"labels_\" + str(all_ticas[j][0])))),eval(\"labels_\" + str(all_ticas[j][0])),rotation=90)\n",
    "            plt.subplot(414)\n",
    "            plt.bar(range(len(eval(\"y_\" + str(all_ticas[j][1])))), eval(\"y_\" + str(all_ticas[j][1])))\n",
    "            plt.xticks(range(len(eval(\"labels_\" + str(all_ticas[j][0])))),eval(\"labels_\" + str(all_ticas[j][1])),rotation=90)\n",
    "            plt.title('Eigenvalue Analysis for tIC' + str(all_ticas[j][0]) + \"/tIC\" + str(all_ticas[j][1]))\n",
    "            plt.tight_layout()\n",
    "            print()\n",
    "            plt.savefig(project_title + '/' + \"eigen_analysis_\" + str(all_ticas[j][0]) + \"_\" + str(all_ticas[j][1]) + \".png\")\n",
    "            plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "def plot_clusters(color_by):\n",
    "    \n",
    "    '''This function projects additional information on top of the tICA landscape. If color_by is set to\n",
    "       cluster, frames are colored by cluster number assignment with stride defined below.\n",
    "       If color_by is set to angle, frames are colored by the number of trans dihedral angles found, as\n",
    "       defined by color_by_cistrans.\n",
    "    '''\n",
    "          \n",
    "    print(\"\\nPlotting clusters...\")\n",
    "    \n",
    "    # Determine bound frames, if any\n",
    "    bound_frames = get_bound_frames()[0]\n",
    "    \n",
    "    # Load tICA coordinates and cluster assignments\n",
    "    tica_coordinates = np.load(project_title + '/' + 'lag_%d_comp_%d.npy' %(tica_lagtime, tica_components))\n",
    "    sequences = np.load(project_title + '/' + 'lag_%d_clusters_%d_sequences.npy' %(tica_lagtime, n_clusters))\n",
    "    \n",
    "    # Initiate and populate arrays for each component\n",
    "    for i in range(tica_components):\n",
    "        exec('tica_' + str(i+1) + ' = []')\n",
    "    for i in range(len(tica_coordinates)):\n",
    "        for j in range(len(tica_coordinates[i])):\n",
    "            for k in range(tica_components):\n",
    "                exec('tica_' + str(k+1) + '.append(tica_coordinates[i][j][k])')\n",
    "    \n",
    "    # Denote stride and a color array for the number of clusters\n",
    "    stride = 128 #int(len(tica_coordinates[0])/100) + 1\n",
    "    cluster_colors = cm.rainbow(np.linspace(0,1,n_clusters))\n",
    "    \n",
    "    # Create and save plots for each tICA component combination, for each trajectory\n",
    "    for j in tqdm.tqdm_notebook(range(len(all_ticas))):\n",
    "        if all_ticas[j][0] < all_ticas[j][1]:\n",
    "            if not os.path.exists(project_title + \"/%d_%d\" %(all_ticas[j][0],all_ticas[j][1])):\n",
    "                os.makedirs(project_title + \"/%d_%d\" %(all_ticas[j][0],all_ticas[j][1]))\n",
    "            angle_colors = []\n",
    "            for k in range(len(trajectory_files)):\n",
    "                legend_elements = []\n",
    "                try: # Retrieve color associated with number of trans dihedral angles\n",
    "                    structure_file = re.sub('.trr','.gro',re.sub('.xtc','.gro',trajectory_files[k]))\n",
    "                    angle_colors += color_by_cistrans(trajectory_files[k],structure_file=structure_file,angle='omega')\n",
    "                except Exception as e:\n",
    "                    angle_colors += color_by_cistrans(trajectory_files[k],structure_file='xtc.gro',angle='omega')\n",
    "\n",
    "                traj_tic1,traj_tic2 = [],[]\n",
    "                plt.figure(j, figsize=(8,5))\n",
    "                # Plot the underlying tICA map\n",
    "                plt.hexbin(eval(\"tica_\"+str(all_ticas[j][0])), eval(\"tica_\"+str(all_ticas[j][1])), bins='log')\n",
    "                for l in range(len(tica_coordinates[k])):\n",
    "                    traj_tic1.append(tica_coordinates[k][l][all_ticas[j][0]-1])\n",
    "                    traj_tic2.append(tica_coordinates[k][l][all_ticas[j][1]-1])\n",
    "\n",
    "                # Plot the strided projection\n",
    "                for l in tqdm.tqdm(range(len(traj_tic1))[::stride]):\n",
    "                    if color_by == 'cluster':\n",
    "                        plt.plot(traj_tic1[l], traj_tic2[l], color=cluster_colors[sequences[k][l]], linestyle=\"\", marker=\"o\")\n",
    "                    if color_by == 'angle':\n",
    "                        try:\n",
    "                            plt.plot(traj_tic1[l], traj_tic2[l], color=angle_colors[l], linestyle=\"\", marker=\"o\")\n",
    "                        except Exception as e:\n",
    "                            print(l,len(angle_colors), len(traj_tic1))\n",
    "                if color_by == 'angle':\n",
    "                    colors = ['pink','red','orange','green','blue','purple','black']\n",
    "                    for l in range(len(colors)): # Create a legend containing colors corresponding to number of angles\n",
    "                        legend_elements.append(Line2D([0], [0], marker='o', color=colors[l], label=\"%d trans\"%l,\n",
    "                            markerfacecolor=colors[l], markersize=8))\n",
    "                if bound_frames[k]: # If bound frames exist\n",
    "                    for m in range(len(bound_frames[k])):\n",
    "                        try:\n",
    "                            bound_x_centers = [ traj_tic1[x] for x in bound_frames[k][m] ]\n",
    "                            bound_y_centers = [ traj_tic2[x] for x in bound_frames[k][m] ]\n",
    "                        except Exception as e:\n",
    "                            print(e,k,m,trajectory_files[k])\n",
    "                        # Project them on top of the trajectory projection in white\n",
    "                        plt.plot(bound_x_centers[::stride], bound_y_centers[::stride], color='w')\n",
    "                # Plot the trajectory's starting point\n",
    "                plt.plot(traj_tic1[0],traj_tic2[0],color='w',marker='*',markersize=24)\n",
    "            plt.xlabel(\"tica_\"+str(all_ticas[j][0]))\n",
    "            plt.ylabel(\"tica_\"+str(all_ticas[j][1]))\n",
    "#            plt.title(trajectory_files[k])\n",
    "            #plt.legend(handles=legend_elements, loc='best')\n",
    "            plt.savefig(project_title + \"/%d_%d/\"%(all_ticas[j][0],all_ticas[j][1]) + \"all_clusters_%d.png\"%k)\n",
    "            plt.close()\n",
    "            \n",
    "\n",
    "def show_transitions():\n",
    "    \n",
    "    # Load tICA coordinates and cluster assignments\n",
    "    n_transitions = 24\n",
    "    tica_coordinates = np.load(project_title + '/' + 'lag_%d_comp_%d.npy' %(tica_lagtime, tica_components))\n",
    "    sequences = np.load(project_title + '/' + 'lag_%d_clusters_%d_sequences.npy' %(tica_lagtime, n_clusters))\n",
    "    centers = np.load(project_title + '/' + 'lag_%d_clusters_%d_center.npy' %(tica_lagtime, n_clusters))\n",
    "    \n",
    "    # Initiate and populate arrays for each component\n",
    "    for i in range(tica_components):\n",
    "        exec('tica_' + str(i+1) + ' = []')\n",
    "    for i in range(len(tica_coordinates)):\n",
    "        for j in range(len(tica_coordinates[i])):\n",
    "            for k in range(tica_components):\n",
    "                exec('tica_' + str(k+1) + '.append(-tica_coordinates[i][j][k])')\n",
    "    \n",
    "    def largest_indices(arr, n):\n",
    "        \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "        flat = arr.flatten()\n",
    "        indices = np.argpartition(flat, -n)[-n:]\n",
    "        indices = indices[np.argsort(-flat[indices])]\n",
    "        return np.unravel_index(indices, arr.shape)\n",
    "    \n",
    "    transitions = np.zeros(shape=(n_clusters,n_clusters))\n",
    "    for i in range(len(sequences)):\n",
    "        for j in range(len(sequences[i])):\n",
    "            try:\n",
    "                transitions[sequences[i][j]][sequences[i][j+1]] += 1\n",
    "            except IndexError as e:\n",
    "                pass\n",
    "\n",
    "    top_transition_indices = largest_indices(transitions,n_transitions)[::-1]\n",
    "    top_transition_counts = transitions[largest_indices(transitions,n_transitions)]\n",
    "    normalized_transition_counts = [x/sum(top_transition_counts) for x in top_transition_counts][::-1]\n",
    "    \n",
    "    counts = np.array([float(len(np.where(np.concatenate(sequences)==i)[0])) for i in range(n_clusters)])\n",
    "    normalized_counts =  counts/float(counts.sum())\n",
    "    percentages = [x*100 for x in normalized_counts]\n",
    "    cluster_colors = cm.rainbow(np.linspace(0,1,n_clusters))\n",
    "    \n",
    "    for j in tqdm.tqdm(range(len(all_ticas))): # For each pair\n",
    "        if all_ticas[j][0] < all_ticas[j][1]:\n",
    "            plt.figure(j, figsize=(20,16))\n",
    "            plt.hexbin(eval(\"tica_\"+str(all_ticas[j][0])), eval(\"tica_\"+str(all_ticas[j][1])), bins='log')\n",
    "            \n",
    "            # plot centers, colored by population\n",
    "            x_centers = [-centers[i][all_ticas[j][0]-1] for i in range(len(centers))]\n",
    "            y_centers = [-centers[i][all_ticas[j][1]-1] for i in range(len(centers))]\n",
    "            \n",
    "            for k in range(len(x_centers)):\n",
    "                plt.plot(x_centers[k], y_centers[k], linestyle='', marker='*', markersize=256*normalized_counts[k],\n",
    "                         color=cluster_colors[int(normalized_counts[k]*100.)])\n",
    "                print(\"Plotting cluster center %d with size %f\"%(k,256.*normalized_counts[k]))\n",
    "                \n",
    "            print(\"\\nPlotting Top Cluster Transitions\")\n",
    "            for k in range(len(top_transition_counts)): # plot top non-self transitions\n",
    "                if top_transition_indices[0][k] != top_transition_indices[1][k]:\n",
    "                    try:\n",
    "                        dx = x_centers[top_transition_indices[1][k]] - x_centers[top_transition_indices[0][k]]\n",
    "                        dy = y_centers[top_transition_indices[1][k]] - y_centers[top_transition_indices[0][k]]\n",
    "                        plt.arrow(x_centers[top_transition_indices[0][k]],dx,\n",
    "                                  y_centers[top_transition_indices[0][k]],dy,\n",
    "                                  color=cluster_colors[k], width=normalized_transition_counts[k],\n",
    "                                  head_width=3.*normalized_transition_counts[k], length_includes_head=True)\n",
    "#                        print(\"\\tPlotting transition Between Clusters %d and %d with head %f and width %f\"\n",
    "#                              %(top_transition_indices[0][k],top_transition_indices[1][k],\n",
    "#                                3.*normalized_transition_counts[k],normalized_transition_counts[k]))\n",
    "                    except IndexError as e:\n",
    "                        pass\n",
    " #               else:\n",
    " #                   print(\"\\tSkipping self-transition of Cluster %d\"%top_transition_indices[0][k])\n",
    "            \n",
    "            plt.plot(eval(\"tica_\"+str(all_ticas[j][0])+'[0]'), eval(\"tica_\"+str(all_ticas[j][1])+'[0]'),\n",
    "             color='w', marker='o',markersize=16)\n",
    "            plt.xlabel('tic'+str(all_ticas[j][0]))\n",
    "            plt.ylabel('tic'+str(all_ticas[j][1]))\n",
    "            plt.title(project_title)\n",
    "            plt.savefig(project_title + '/' + 'tica_'+str(all_ticas[j][0])+'_'+str(all_ticas[j][1])+'_transitions.png')\n",
    "            plt.close()\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a directory by the name project_title, to populate with results\n",
    "project_title = 'Na_ACN'\n",
    "# nmer and cyclic used for single molecule trajectories, to calculate dihedrals\n",
    "# and will likely be deprecated soonish.\n",
    "nmer = 6\n",
    "cyclic = True\n",
    "# cut-off for binding distance in nm\n",
    "bound_cutoff = 0.30\n",
    "# general structure file and trajectory files denoted below\n",
    "structure_file = 'xtc.gro'\n",
    "trajectory_files = sorted(glob.glob('*xtc')) + sorted(glob.glob('*trr')) #sorted(glob.glob(\"1_a_n*.trr\")) #['traj_00.xtc','traj_01.xtc','traj_02.xtc'] + sorted(glob.glob(\"0*.trr\")) + sorted(glob.glob(\"H030*trr\"))\n",
    "# tICA parameters\n",
    "tica_lagtime = 100\n",
    "tica_components = 8\n",
    "n_clusters = 100\n",
    "n_timescales = 8\n",
    "time_step = 1.0 # ns multiplier of timescales and lagtimes in implied timescale plot\n",
    "lagtimes = np.array([1,2,4,8,16,32,64,128,256,512,1024])\n",
    "# which features to use\n",
    "tica_metric = 'distance' # 'distance / dihedral'\n",
    "if tica_metric in ['dihedral', 'mixed']:\n",
    "    angle = 'omega' # phi/psi/omega\n",
    "# cluster method\n",
    "cluster_method = 'kcenters' # 'kcenters/kmeans'\n",
    "\n",
    "# select which functions to run (boolean toggle)\n",
    "calculate_features = True # calculate and save features\n",
    "calculate_components = True # calculate and save tICA components / eigenvectors/values\n",
    "enspara_msm = 'False'\n",
    "multiple_trajectory_analysis = False # create a plot for each trajectory in trajectory_files, \n",
    "                                     # showing its projection over the combined tICA space\n",
    "movie_analysis = False # creates a movie based on the trajectory data and metric specified\n",
    "eigen_analysis = False # outputs plots of eigenvectors and corresponding features for each component in all_ticas\n",
    "cluster_plot = True # outputs a plot with colors showing number of trans angles or cluster identity\n",
    "color_by = 'angle' # angle/cluster\n",
    "verbose = False # let's you choose to have a bunch of junk printed to stdout (debug)\n",
    "\n",
    "all_ticas = list(itertools.permutations(range(1,tica_components+1), 2)) # all combinations\n",
    "all_ticas = [[1,2]]  #[1,3],[2,3],[3,4],[5,6]] # just show analysis for first two components\n",
    "# analyzing more than one set may generate thousands more images (movie analysis)\n",
    "\n",
    "cluster_percentage_cutoff = n_clusters/64 # clusters with a relative population less than this\n",
    "                              # number will not be labeled i.e. 0 : all clusters labeled\n",
    "    \n",
    "if socket.gethostname() == 'syzygy':\n",
    "    debug_prefix = '/media/matt/ext'\n",
    "else:\n",
    "    debug_prefix = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating distances...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'feature_labels' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4a74e2090b99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalculate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtica_metric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'distance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfeature_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtica_metric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dihedral'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfeature_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_dihedrals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-d48d6152a30b>\u001b[0m in \u001b[0;36mcalculate_distances\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_title\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'distance_out_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'feature_labels' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# This cell runs the analysis given the parameters entered above\n",
    "\n",
    "#deprecated\n",
    "#%install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "#%load_ext autotime\n",
    "\n",
    "if not os.path.exists(project_title):\n",
    "    os.makedirs(project_title)\n",
    "\n",
    "if calculate_features:\n",
    "    if tica_metric == 'distance':\n",
    "        feature_labels = calculate_distances()\n",
    "    elif tica_metric == 'dihedral':\n",
    "        feature_labels = calculate_dihedrals()\n",
    "    else:\n",
    "        print(\"Specify either distance or dihedral as the tica_metric\")\n",
    "        sys.exit()\n",
    "if calculate_components:\n",
    "    eigenvectors = calculate_tica_components()\n",
    "if multiple_trajectory_analysis:\n",
    "    trajectory_trace()\n",
    "if movie_analysis:\n",
    "    if tica_metric == 'distance':\n",
    "        thetas = distance_tica_movie()\n",
    "    if tica_metric == 'dihedral':\n",
    "        dihedral_tica_movie()\n",
    "if eigen_analysis:\n",
    "    eigenvalue_analysis()\n",
    "if cluster_plot:\n",
    "    plot_clusters(color_by=color_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choices = [[['c', 'c', 'c', 'c', 'c', 'c']],\n",
    "     [['c', 'c', 'c', 'c', 'c', 't'],['c', 'c', 'c', 't', 'c', 'c'],['c', 't', 'c', 'c', 'c', 'c']],\n",
    "     [['c', 'c', 'c', 'c', 't', 'c'],['c', 'c', 't', 'c', 'c', 'c'],['t', 'c', 'c', 'c', 'c', 'c']],\n",
    "     [['c', 'c', 'c', 'c', 't', 't'],['c', 'c', 't', 't', 'c', 'c'],['t', 't', 'c', 'c', 'c', 'c']],\n",
    "     [['c', 'c', 'c', 't', 't', 'c'],['c', 't', 't', 'c', 'c', 'c'],['t', 'c', 'c', 'c', 'c', 't']],\n",
    "     [['c', 'c', 'c', 't', 'c', 't'],['c', 't', 'c', 't', 'c', 'c'],['c', 't', 'c', 'c', 'c', 't']],\n",
    "     [['c', 'c', 't', 'c', 't', 'c'],['t', 'c', 'c', 'c', 't', 'c'],['t', 'c', 't', 'c', 'c', 'c']],\n",
    "     [['c', 'c', 't', 'c', 'c', 't'],['t', 'c', 'c', 't', 'c', 'c']],\n",
    "     [['c', 't', 'c', 'c', 't', 'c']],\n",
    "     [['c', 'c', 'c', 't', 't', 't'],['c', 't', 't', 't', 'c', 'c'],['t', 't', 'c', 'c', 'c', 't']],\n",
    "     [['c', 'c', 't', 't', 't', 'c'],['t', 'c', 'c', 'c', 't', 't'],['t', 't', 't', 'c', 'c', 'c']],\n",
    "     [['c', 'c', 't', 'c', 't', 't'],['t', 'c', 't', 't', 'c', 'c'],['t', 't', 'c', 'c', 't', 'c']],\n",
    "     [['c', 't', 'c', 't', 't', 'c'],['c', 't', 't', 'c', 'c', 't'],['t', 'c', 'c', 't', 'c', 't']],\n",
    "     [['c', 'c', 't', 't', 'c', 't'],['c', 't', 'c', 'c', 't', 't'],['t', 't', 'c', 't', 'c', 'c']],\n",
    "     [['c', 't', 't', 'c', 't', 'c'],['t', 'c', 'c', 't', 't', 'c'],['t', 'c', 't', 'c', 'c', 't']],\n",
    "     [['c', 't', 'c', 't', 'c', 't']],\n",
    "     [['t', 'c', 't', 'c', 't', 'c']],\n",
    "     [['c', 'c', 't', 't', 't', 't'],['t', 't', 'c', 'c', 't', 't'],['t', 't', 't', 't', 'c', 'c']],\n",
    "     [['c', 't', 't', 't', 't', 'c'],['t', 'c', 'c', 't', 't', 't'],['t', 't', 't', 'c', 'c', 't']],\n",
    "     [['c', 't', 'c', 't', 't', 't'],['c', 't', 't', 't', 'c', 't'],['t', 't', 'c', 't', 'c', 't']],\n",
    "     [['t', 'c', 't', 'c', 't', 't'],['t', 'c', 't', 't', 't', 'c'],['t', 't', 't', 'c', 't', 'c']],\n",
    "     [['c', 't', 't', 'c', 't', 't']],\n",
    "     [['t', 'c', 't', 't', 'c', 't'],['t', 't', 'c', 't', 't', 'c']],\n",
    "     [['c', 't', 't', 't', 't', 't'],['t', 't', 'c', 't', 't', 't'],['t', 't', 't', 't', 'c', 't']],\n",
    "     [['t', 'c', 't', 't', 't', 't'],['t', 't', 't', 'c', 't', 't'],['t', 't', 't', 't', 't', 'c']],\n",
    "     [['t', 't', 't', 't', 't', 't']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_transitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's figure this vamp shit out\n",
    "import pyemma\n",
    "print(sorted(glob.glob('0/*npy')))\n",
    "data = [np.load(i) for i in sorted(glob.glob('0/*out*npy'))]\n",
    "cluster = pyemma.coordinates.cluster_kmeans(data, k=100, max_iter=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#its = pyemma.msm.its(cluster.dtrajs, lags=[1, 2, 4,8,16,32,64,128,256,512,1024,2048,4196,8392], nits=3, errors='bayes')\n",
    "#pyemma.plots.plot_implied_timescales(its, ylog=False)\n",
    "clusters = [64, 128, 256, 512]\n",
    "fig, axes = plt.subplots(2, len(clusters), figsize=(12, 6))\n",
    "for i, k in enumerate(clusters):\n",
    "    cluster = pyemma.coordinates.cluster_kmeans(data, k=k, max_iter=128, stride=10)\n",
    "    pyemma.plots.plot_implied_timescales(\n",
    "        pyemma.msm.its(cluster.dtrajs, lags=[1,2,4,8,16,32,64,128], nits=4, errors='bayes'),\n",
    "        ax=axes[1, i], units='ns')\n",
    "    axes[1, i].set_ylim(1, 150)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAMP_score = pyemma.msm.estimators.score(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enspara.msm import MSM, builders\n",
    "from enspara.msm import MSM, builders\n",
    "\n",
    "# build the MSM fitter with a lag time of 100 (frames) and\n",
    "# using the transpose method\n",
    "msm = MSM(lag_time=100, method=builders.transpose)\n",
    "\n",
    "# fit the MSM to your assignments (a numpy ndarray or ragged array)\n",
    "msm.fit(assignments)\n",
    "\n",
    "print(msm.tcounts_)\n",
    "print(msm.tprobs_)\n",
    "print(msm.eq_probs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nglview as ng\n",
    "import mdtraj as md\n",
    "import ipywidgets\n",
    "v = ng.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0bb41c7f38413394999520aac0c286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>NGLWidget</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v._ngl_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
